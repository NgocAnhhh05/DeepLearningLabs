{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13453298,"sourceType":"datasetVersion","datasetId":8539588}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"de36df80","cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:05:36.787339Z","iopub.execute_input":"2025-11-06T08:05:36.787964Z","iopub.status.idle":"2025-11-06T08:05:45.736363Z","shell.execute_reply.started":"2025-11-06T08:05:36.787938Z","shell.execute_reply":"2025-11-06T08:05:45.735772Z"}},"outputs":[],"execution_count":1},{"id":"25b3ef30","cell_type":"code","source":"class VinaFoodDataLoader:\n    def __init__(self, batch_size=64, num_workers=2, data_dir='/kaggle/input/vinafood21/VinaFood21', input_image_size=224):\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.data_dir = data_dir\n        self.input_image_size = input_image_size\n\n        self.transform = transforms.Compose([\n            # 1. Resize image into 224 x 224\n            transforms.Resize((input_image_size, input_image_size)),\n\n            # 2. Convert into PyTorch Tensor\n            transforms.ToTensor(),\n\n            # 3. Normalize\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n    def get_train_loader(self):\n        train_path = os.path.join(self.data_dir, 'train')\n        train_dataset = datasets.ImageFolder(root=train_path, transform=self.transform)\n        train_loader = DataLoader(dataset=train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n        print(f\"Loaded {len(train_dataset)} training samples from {train_path}. Found {len(train_dataset.classes)} classes\")\n        self.num_classes = len(train_dataset.classes)\n        return train_loader\n\n        # Mỗi thư mục con tương ứng với 1 nhãn (class) -> gán label cho từng ảnh dựa theo thứ tự thư mục con được sắp xếp alphabetically\n\n    def get_test_loader(self):\n        test_path = os.path.join(self.data_dir, 'test')\n        test_dataset = datasets.ImageFolder(root=test_path, transform=self.transform)\n        test_loader = DataLoader(dataset=test_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n        print(f\"Loaded {len(test_dataset)} test samples from {test_path}\")\n        return test_loader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:06:02.989630Z","iopub.execute_input":"2025-11-06T08:06:02.989986Z","iopub.status.idle":"2025-11-06T08:06:02.997410Z","shell.execute_reply.started":"2025-11-06T08:06:02.989967Z","shell.execute_reply":"2025-11-06T08:06:02.996578Z"}},"outputs":[],"execution_count":2},{"id":"e03f6024-71fa-48d9-b55e-50dae9579107","cell_type":"code","source":"class BasicBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n\n        \"\"\"\n        Args:\n            in_channels: Number of input channels\n            out_channels: Number of output channels\n            stride: Stride for the first convolutional layer\n            downsample(nn.Module, optional): Shortcut connection if dimensions need to change\n        \"\"\"\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        # padding = 1 to maintain the same size of input x\n\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        # Shortcut connection\n        self.downsample = downsample\n\n        # if downsample == None -> create if input != output\n\n        if self.downsample is None and (stride != 1 or in_channels != out_channels):\n            self.downsample = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward (self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        if self.downsample is not None:\n            identity = self.downsample(x)\n        out += identity\n        out = self.relu(out)\n        return out\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:06:07.516042Z","iopub.execute_input":"2025-11-06T08:06:07.516584Z","iopub.status.idle":"2025-11-06T08:06:07.523472Z","shell.execute_reply.started":"2025-11-06T08:06:07.516558Z","shell.execute_reply":"2025-11-06T08:06:07.522887Z"}},"outputs":[],"execution_count":3},{"id":"a2aa74c7-3719-4d32-8b21-7a9c32e871aa","cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes):\n        super(ResNet, self).__init__()\n        self.in_channels = 64 # Output of conv1 (input of conv2_x)\n\n        # Initialize\n        # Input: (N, 3, 224, 224)\n        # Output: (N, 64, 112, 112)\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n        # Padding = 3 được suy ra từ công thức tính output size\n        self.bn1 = nn.BatchNorm2d(64)\n\n        # 2. Max Pooling 1\n        # Input: (N, 64, 112, 112)\n        # Output: (N, 64, 56, 56)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)\n\n        # 3. Residual Block\n        # 3.1 Conv2_x: Output: (N, 64, 56, 56)\n        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n        # Max Pooling (Inter-stage 1)\n        # Input: (N, 64, 56, 56) -> Output: (N, 64, 28, 28)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n\n        # 3.2 Conv3_x: Output(N, 128, 28, 28)\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=1)\n        # Max Pooling (Inter-stage 2)\n        # Input: (N, 128, 28, 28) -> Output: (N, 128, 14, 14)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n\n\n        # 3.3 Conv4_x: Output(N, 256, 14, 14)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=1)\n        # Max Pooling (Inter-stage 3)\n        # Input: (N, 256, 14, 14) -> Output: (N, 256, 7, 7)\n        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n\n\n         # 3.4 Conv5_x: Output(N, 512, 7, 7)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=1)\n\n        # 4. Average Pooling\n        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n\n        # 5. FC\n        self.fc = nn.Linear(512, num_classes)\n\n        # Initialize parameters for Cons/ BN layer\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, block, out_channels, num_blocks, stride):\n        \"\"\"\n        Helper function to create a sequential layer  (stage - ex: conv2_x, conv3_x, ...) of residual blocks\n            - Each stage include many residual similar blocks (ex: 2 blocks in ResNet-18)\n        \"\"\"\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        layers = []\n        # Block đầu tiên trong stage có thể cần projection shortcut nếu số kênh thay đổi\n        layers.append(block(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels # Cập nhật in_channels cho các block tiếp theo\n\n        # Các block còn lại trong stage sẽ có identity shortcut (stride=1, in_channels == out_channels)\n        for _ in range(1, num_blocks):\n            layers.append(block(self.in_channels, out_channels, stride=1))\n\n        return nn.Sequential(*layers)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.maxpool1(x)\n\n        x = self.layer1(x) # Conv2_x\n        x = self.maxpool2(x)\n\n        x = self.layer2(x) # Conv3_x\n        x = self.maxpool3(x)\n\n        x = self.layer3(x) # Conv4_x\n        x = self.maxpool4(x)\n\n        x = self.layer4(x) # Conv5_x\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n\n        logits = self.fc(x)\n        probabilities = F.softmax(logits, dim=1)\n        return logits, probabilities\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:06:11.347208Z","iopub.execute_input":"2025-11-06T08:06:11.347794Z","iopub.status.idle":"2025-11-06T08:06:11.359140Z","shell.execute_reply.started":"2025-11-06T08:06:11.347769Z","shell.execute_reply":"2025-11-06T08:06:11.358320Z"}},"outputs":[],"execution_count":4},{"id":"8aa23325-d878-4edf-9810-b0a9b3a5a3ea","cell_type":"code","source":"def resnet18(num_classes=21):\n        # layer = [num_blocks_in_conv2_x, num_blocks_in_conv3_x, num_blocks_in_conv4_x, num_blocks_in_conv5_x]\n        return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=21)\n\n# Vì ResNet có nhiều version nên thay vì gọi class ResNet trên thì sẽ xây dụng một class cho nhiều version ResNet -> xây dụng một hàm để gọi riêng từng version ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:06:21.052425Z","iopub.execute_input":"2025-11-06T08:06:21.053137Z","iopub.status.idle":"2025-11-06T08:06:21.056734Z","shell.execute_reply.started":"2025-11-06T08:06:21.053114Z","shell.execute_reply":"2025-11-06T08:06:21.055951Z"}},"outputs":[],"execution_count":5},{"id":"ce6f6fdc","cell_type":"code","source":"def evaluate_model(model, data_loader, device):\n    model.eval()\n    all_preds = []\n    all_targets = []\n    with torch.no_grad():\n        for data, target in tqdm(data_loader, desc=\"Evaluating\"):\n            data, target = data.to(device), target.to(device)\n            _, probabilities = model(data)\n            predictions = probabilities.argmax(dim=1)\n            all_preds.extend(predictions.cpu().numpy())\n            all_targets.extend(target.cpu().numpy())\n\n    all_preds = np.array(all_preds)\n    all_targets = np.array(all_targets)\n    print(\"Overall evaluation metrics\")\n    overall_accuracy = accuracy_score(all_targets, all_preds)\n    print(f\"Accuracy: {overall_accuracy:.4f}\")\n\n    overall_recall = recall_score(all_targets, all_preds, average='macro', zero_division=0)\n    print(f\"Recall: {overall_recall:.4f}\")\n\n    overall_precision = precision_score(all_targets, all_preds, average='macro', zero_division=0)\n    print(f\"Precision: {overall_accuracy:.4f}\")\n\n    overall_f1 = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n    print(f\"F1: {overall_accuracy:.4f}\")\n\n    num_classes = len(np.unique(all_targets))\n    per_class_results = {}\n\n    # print(f\"Per-class evaluation metrics\")\n    # for i in range (num_classes):\n    #     class_target = (all_targets == i).astype(int)\n    #     class_pred = (all_preds == i).astype(int)\n\n    #     accuracy = accuracy_score(class_target, class_pred)\n    #     precision = precision_score(class_target, class_pred, zero_division=0)\n    #     recall = recall_score(class_target, class_pred, zero_division=0)\n    #     f1 = f1_score(class_target, class_pred, zero_division=0)\n\n    #     per_class_results[i] = {\n    #         'accuracy': accuracy,\n    #         'precision': precision,\n    #         'recall': recall,\n    #         'f1': f1\n    #     }\n    #     print(f\"Class {i}: \\n Accuracy: {accuracy:.4f} \\n Recall: {recall:.4f} \\n Precision: {precision:.4f} \\n F1: {f1:.4f}\")\n    return {\n        'overall': {\n            'accuracy': overall_accuracy,\n            'precision': overall_precision,\n            'recall': overall_recall,\n            'f1': overall_f1\n        }\n        # 'per_class': per_class_results\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:06:25.407144Z","iopub.execute_input":"2025-11-06T08:06:25.407827Z","iopub.status.idle":"2025-11-06T08:06:25.414295Z","shell.execute_reply.started":"2025-11-06T08:06:25.407802Z","shell.execute_reply":"2025-11-06T08:06:25.413600Z"}},"outputs":[],"execution_count":6},{"id":"52e29943","cell_type":"code","source":"class Trainer:\n    def __init__(self, model, train_loader, test_loader, device, learning_rate=0.01, epochs=5, save_dir='/kaggle/working/checkpoints/'):\n        self.model = model\n        self.train_loader = train_loader\n        self.test_loader = test_loader\n        self.device = device\n        self.learning_rate = learning_rate\n        self.epochs = epochs\n        self.save_dir = save_dir\n\n        self.best_accuracy = 0.0\n\n        self.criterion = nn.CrossEntropyLoss()\n\n        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n        os.makedirs(self.save_dir, exist_ok=True)\n\n    def train_epoch(self, epoch):\n        self.model.train()\n        total_loss = 0\n        for batch_idx, (data, target) in enumerate(tqdm(self.train_loader, desc=f'Training {epoch}/{self.epochs}')):\n            data, target = data.to(self.device), target.to(self.device)\n\n            self.optimizer.zero_grad()\n            _,logits = self.model(data)\n            loss = self.criterion(logits, target)\n            loss.backward()\n            self.optimizer.step()\n\n            total_loss += loss\n\n        avg_loss = total_loss/len(self.train_loader)\n        print(f\"Epoch {epoch} Training loss: {avg_loss:.4f}\")\n        return avg_loss\n\n    def train(self):\n        print(f\"Full training on {self.device} for {self.epochs} with {self.learning_rate}\")\n        for epoch in range(1, self.epochs + 1):\n            self.train_epoch(epoch)\n\n            metrics = evaluate_model(self.model, self.test_loader, self.device)\n            current_accuracy = metrics['overall']['accuracy']\n            if current_accuracy > self.best_accuracy:\n                self.best_accuracy = current_accuracy\n                model_path = os.path.join(self.save_dir, 'best_model_assigment_03.pt')\n                torch.save(self.model.state_dict(), model_path)\n                print(f\"Save new model version with accurcay = {self.best_accuracy:.4f}\")\n        print(\"Training_finished\")\n        print(f\"Best model version is saved at {model_path} with accuracy = {self.best_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:06:30.977970Z","iopub.execute_input":"2025-11-06T08:06:30.978489Z","iopub.status.idle":"2025-11-06T08:06:30.986306Z","shell.execute_reply.started":"2025-11-06T08:06:30.978467Z","shell.execute_reply":"2025-11-06T08:06:30.985596Z"}},"outputs":[],"execution_count":7},{"id":"97a16dc8-b5e2-4396-abec-f8ef244c038b","cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device}\")\n\nprint(\"Load data\")\ndata_loader = VinaFoodDataLoader()\ntrain_loader = data_loader.get_train_loader()\ntest_loader = data_loader.get_test_loader()\n\nnum_classes = data_loader.num_classes\nprint(f\"Number of classes: {num_classes}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:06:34.815673Z","iopub.execute_input":"2025-11-06T08:06:34.816341Z","iopub.status.idle":"2025-11-06T08:06:52.738090Z","shell.execute_reply.started":"2025-11-06T08:06:34.816315Z","shell.execute_reply":"2025-11-06T08:06:52.737374Z"}},"outputs":[{"name":"stdout","text":"Using cuda\nLoad data\nLoaded 10044 training samples from /kaggle/input/vinafood21/VinaFood21/train. Found 21 classes\nLoaded 6682 test samples from /kaggle/input/vinafood21/VinaFood21/test\nNumber of classes: 21\n","output_type":"stream"}],"execution_count":8},{"id":"3122d8df-2da8-4ded-bbe8-097c89cb4940","cell_type":"code","source":"print(\"Build model\")\nmodel = resnet18(21).to(device)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:11:25.593904Z","iopub.execute_input":"2025-11-06T08:11:25.594192Z","iopub.status.idle":"2025-11-06T08:11:25.788062Z","shell.execute_reply.started":"2025-11-06T08:11:25.594169Z","shell.execute_reply":"2025-11-06T08:11:25.787366Z"}},"outputs":[{"name":"stdout","text":"Build model\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (maxpool4): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=21, bias=True)\n)\n","output_type":"stream"}],"execution_count":11},{"id":"34ead30a","cell_type":"code","source":"print(\"Start training\")\ntrainer = Trainer(\n    model=model,\n    train_loader=train_loader,\n    test_loader=test_loader,\n    device=device,\n    learning_rate=0.01,\n    epochs=3,\n    save_dir= '/kaggle/working/checkpoints/'\n)\ntrainer.train()\n\nprint(\"Evaluate with best model\")\nbest_model_path = '/kaggle/working/checkpoints/best_model_assignment_02.pt'\nfinal_model = resnet18(num_clases=num_classes).to(device)\nfinal_model.load_state_dict(torch.load(best_model_path, map_location=device))\nfinal_metrics = evaluate_model(\n    model=final_model,\n    data_loader=test_loader,\n    device=device\n)\nprint(\"Final overall metrics\")\nfor k, v in final_model['overall'].items():\n    print(f\"{k}: {v}\")\n\n# print(\"Final per-class metrics\")\n# for label, metrics in final_metrics['per_class'].items():\n#     print (f\"Class {label}: \\n Acc: {metrics['accuracy']:.4f} \\n Precision: {metrics['precision']:.4f} \\n Recall: {metrics['recall']:.4f} \\n F1: {metrics['f1']:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T08:11:29.960547Z","iopub.execute_input":"2025-11-06T08:11:29.960825Z","iopub.status.idle":"2025-11-06T08:19:04.007150Z","shell.execute_reply.started":"2025-11-06T08:11:29.960807Z","shell.execute_reply":"2025-11-06T08:19:04.006037Z"}},"outputs":[{"name":"stdout","text":"Start training\nFull training on cuda for 3 with 0.01\n","output_type":"stream"},{"name":"stderr","text":"Training 1/3:   1%|          | 1/157 [00:02<06:15,  2.41s/it]/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\nTraining 1/3: 100%|██████████| 157/157 [01:39<00:00,  1.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Training loss: 3.0336\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 105/105 [01:07<00:00,  1.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Overall evaluation metrics\nAccuracy: 0.0792\nRecall: 0.0473\nPrecision: 0.0792\nF1: 0.0792\nSave new model version with accurcay = 0.0792\n","output_type":"stream"},{"name":"stderr","text":"Training 2/3:  62%|██████▏   | 97/157 [00:51<00:31,  1.90it/s]/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\nTraining 2/3: 100%|██████████| 157/157 [01:21<00:00,  1.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Training loss: 3.0356\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 105/105 [00:57<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Overall evaluation metrics\nAccuracy: 0.0908\nRecall: 0.0476\nPrecision: 0.0908\nF1: 0.0908\nSave new model version with accurcay = 0.0908\n","output_type":"stream"},{"name":"stderr","text":"Training 3/3:  31%|███       | 48/157 [00:26<00:53,  2.03it/s]/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\nTraining 3/3: 100%|██████████| 157/157 [01:27<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Training loss: 3.0326\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 105/105 [00:59<00:00,  1.77it/s]","output_type":"stream"},{"name":"stdout","text":"Overall evaluation metrics\nAccuracy: 0.0908\nRecall: 0.0476\nPrecision: 0.0908\nF1: 0.0908\nTraining_finished\nBest model version is saved at /kaggle/working/checkpoints/best_model_assigment_03.pt with accuracy = 0.09084106554923675\nEvaluate with best model\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/449690273.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluate with best model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/working/checkpoints/best_model_assignment_02.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_clases\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m final_metrics = evaluate_model(\n","\u001b[0;31mNameError\u001b[0m: name 'GoogleNet' is not defined"],"ename":"NameError","evalue":"name 'GoogleNet' is not defined","output_type":"error"}],"execution_count":12}]}