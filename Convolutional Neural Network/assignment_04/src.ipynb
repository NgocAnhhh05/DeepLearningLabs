{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc50bbf2-5613-439f-b014-d845c6678875",
   "metadata": {},
   "source": [
    "# Assignment 04: Use pretrained ResNet50 from Hugging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de36df80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T09:31:50.526204Z",
     "iopub.status.busy": "2025-11-06T09:31:50.525839Z",
     "iopub.status.idle": "2025-11-06T09:32:21.231877Z",
     "shell.execute_reply": "2025-11-06T09:32:21.231287Z",
     "shell.execute_reply.started": "2025-11-06T09:31:50.526182Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 09:32:05.058588: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762421525.279506      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762421525.341918      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b3ef30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T09:31:27.971170Z",
     "iopub.status.busy": "2025-11-06T09:31:27.970462Z",
     "iopub.status.idle": "2025-11-06T09:31:27.980722Z",
     "shell.execute_reply": "2025-11-06T09:31:27.980129Z",
     "shell.execute_reply.started": "2025-11-06T09:31:27.971143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VinaFoodDataLoader:\n",
    "    def __init__(self, batch_size=64, num_workers=2, data_dir='/kaggle/input/vinafood21/VinaFood21', image_processor=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        if image_processor is None:\n",
    "            raise ValueError(\"image_processor must be provided for VinaFoodDataLoader in fine-tuning setup\")\n",
    "\n",
    "        self.image_processor = image_processor\n",
    "        self.transform_train = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(image_processor.size[\"shortest_edge\"]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(image_processor.image_mean, image_processor.image_std)\n",
    "        ])\n",
    "\n",
    "        self.transform_test = transforms.Compose([\n",
    "            transforms.Resize(image_processor.size[\"shortest_edge\"]),\n",
    "            transforms.CenterCrop(image_processor.size[\"shortest_edge\"]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(image_processor.image_mean, image_processor.image_std)\n",
    "        ])\n",
    "\n",
    "    def get_train_loader(self):\n",
    "        train_path = os.path.join(self.data_dir, 'train')\n",
    "        train_dataset = datasets.ImageFolder(root=train_path, transform=self.transform_train)\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "        print(f\"Loaded {len(train_dataset)} training samples from {train_path}. Found {len(train_dataset.classes)} classes\")\n",
    "        self.num_classes = len(train_dataset.classes)\n",
    "        return train_loader\n",
    "\n",
    "        # Mỗi thư mục con tương ứng với 1 nhãn (class) -> gán label cho từng ảnh dựa theo thứ tự thư mục con được sắp xếp alphabetically\n",
    "\n",
    "    def get_test_loader(self):\n",
    "        test_path = os.path.join(self.data_dir, 'test')\n",
    "        test_dataset = datasets.ImageFolder(root=test_path, transform=self.transform_test)\n",
    "        test_loader = DataLoader(dataset=test_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n",
    "        print(f\"Loaded {len(test_dataset)} test samples from {test_path}\")\n",
    "        return test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6f6fdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T09:42:11.232966Z",
     "iopub.status.busy": "2025-11-06T09:42:11.232106Z",
     "iopub.status.idle": "2025-11-06T09:42:11.240396Z",
     "shell.execute_reply": "2025-11-06T09:42:11.239754Z",
     "shell.execute_reply.started": "2025-11-06T09:42:11.232937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            logits  = output.logits\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "            predictions = probabilities.argmax(dim=1)\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    print(\"Overall evaluation metrics\")\n",
    "    overall_accuracy = accuracy_score(all_targets, all_preds)\n",
    "    print(f\"Accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    "    overall_recall = recall_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    print(f\"Recall: {overall_recall:.4f}\")\n",
    "\n",
    "    overall_precision = precision_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    print(f\"Precision: {overall_accuracy:.4f}\")\n",
    "\n",
    "    overall_f1 = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    print(f\"F1: {overall_accuracy:.4f}\")\n",
    "\n",
    "    num_classes = len(np.unique(all_targets))\n",
    "    per_class_results = {}\n",
    "\n",
    "    # print(f\"Per-class evaluation metrics\")\n",
    "    # for i in range (num_classes):\n",
    "    #     class_target = (all_targets == i).astype(int)\n",
    "    #     class_pred = (all_preds == i).astype(int)\n",
    "\n",
    "    #     accuracy = accuracy_score(class_target, class_pred)\n",
    "    #     precision = precision_score(class_target, class_pred, zero_division=0)\n",
    "    #     recall = recall_score(class_target, class_pred, zero_division=0)\n",
    "    #     f1 = f1_score(class_target, class_pred, zero_division=0)\n",
    "\n",
    "    #     per_class_results[i] = {\n",
    "    #         'accuracy': accuracy,\n",
    "    #         'precision': precision,\n",
    "    #         'recall': recall,\n",
    "    #         'f1': f1\n",
    "    #     }\n",
    "    #     print(f\"Class {i}: \\n Accuracy: {accuracy:.4f} \\n Recall: {recall:.4f} \\n Precision: {precision:.4f} \\n F1: {f1:.4f}\")\n",
    "    return {\n",
    "        'overall': {\n",
    "            'accuracy': overall_accuracy,\n",
    "            'precision': overall_precision,\n",
    "            'recall': overall_recall,\n",
    "            'f1': overall_f1\n",
    "        }\n",
    "        # 'per_class': per_class_results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52e29943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T09:43:40.178279Z",
     "iopub.status.busy": "2025-11-06T09:43:40.177963Z",
     "iopub.status.idle": "2025-11-06T09:43:40.186573Z",
     "shell.execute_reply": "2025-11-06T09:43:40.185873Z",
     "shell.execute_reply.started": "2025-11-06T09:43:40.178259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, test_loader, device, learning_rate=0.01, epochs=5, save_dir='/kaggle/working/checkpoints/'):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.best_accuracy = 0.0\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(self.train_loader, desc=f'Training {epoch}/{self.epochs}')):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(pixel_values=data)\n",
    "            logits = outputs.logits\n",
    "            loss = self.criterion(logits, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss\n",
    "\n",
    "        avg_loss = total_loss/len(self.train_loader)\n",
    "        print(f\"Epoch {epoch} Training loss: {avg_loss:.4f}\")\n",
    "        return avg_loss\n",
    "\n",
    "    def train(self):\n",
    "        print(f\"Full training on {self.device} for {self.epochs} with {self.learning_rate}\")\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            self.train_epoch(epoch)\n",
    "\n",
    "            metrics = evaluate_model(self.model, self.test_loader, self.device)\n",
    "            current_accuracy = metrics['overall']['accuracy']\n",
    "            if current_accuracy > self.best_accuracy:\n",
    "                self.best_accuracy = current_accuracy\n",
    "                model_path = os.path.join(self.save_dir, 'best_model_assigment_02.pt')\n",
    "                torch.save(self.model.state_dict(), model_path)\n",
    "                print(f\"Save new model version with accurcay = {self.best_accuracy:.4f}\")\n",
    "        print(\"Training_finished\")\n",
    "        print(f\"Best model version is saved at {model_path} with accuracy = {self.best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6a23a6-bd33-4b04-9665-299b6233a0a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T09:33:04.822654Z",
     "iopub.status.busy": "2025-11-06T09:33:04.821559Z",
     "iopub.status.idle": "2025-11-06T09:33:04.826749Z",
     "shell.execute_reply": "2025-11-06T09:33:04.826069Z",
     "shell.execute_reply.started": "2025-11-06T09:33:04.822630Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812d6b1f-7e54-490b-b314-f8d254b9993f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T09:33:16.961173Z",
     "iopub.status.busy": "2025-11-06T09:33:16.960876Z",
     "iopub.status.idle": "2025-11-06T09:33:17.394913Z",
     "shell.execute_reply": "2025-11-06T09:33:17.394225Z",
     "shell.execute_reply.started": "2025-11-06T09:33:16.961150Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Image Processor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025005ab693e400c8b4551133f4da629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/266 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/resnet-50\"\n",
    "print(\"Load Image Processor\")\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a16dc8-b5e2-4396-abec-f8ef244c038b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T09:33:20.542073Z",
     "iopub.status.busy": "2025-11-06T09:33:20.541743Z",
     "iopub.status.idle": "2025-11-06T09:34:13.263318Z",
     "shell.execute_reply": "2025-11-06T09:34:13.262578Z",
     "shell.execute_reply.started": "2025-11-06T09:33:20.542048Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data\n",
      "Loaded 10044 training samples from /kaggle/input/vinafood21/VinaFood21/train. Found 21 classes\n",
      "Loaded 6682 test samples from /kaggle/input/vinafood21/VinaFood21/test\n",
      "Number of classes: 21\n"
     ]
    }
   ],
   "source": [
    "print(\"Load data\")\n",
    "data_loader = VinaFoodDataLoader(image_processor = image_processor)\n",
    "train_loader = data_loader.get_train_loader()\n",
    "test_loader = data_loader.get_test_loader()\n",
    "\n",
    "num_classes = data_loader.num_classes\n",
    "print(f\"Number of classes: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7e6b2a-9000-4b98-b5d8-c97299ab06b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T09:34:37.846082Z",
     "iopub.status.busy": "2025-11-06T09:34:37.845364Z",
     "iopub.status.idle": "2025-11-06T09:34:43.322204Z",
     "shell.execute_reply": "2025-11-06T09:34:43.321535Z",
     "shell.execute_reply.started": "2025-11-06T09:34:37.846055Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8218417667a04a2892283d716c4368d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86726f0bcbc545c4982d023ffa5de0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "ResNetForImageClassification(\n",
      "  (resnet): ResNetModel(\n",
      "    (embedder): ResNetEmbeddings(\n",
      "      (embedder): ResNetConvLayer(\n",
      "        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (encoder): ResNetEncoder(\n",
      "      (stages): ModuleList(\n",
      "        (0): ResNetStage(\n",
      "          (layers): Sequential(\n",
      "            (0): ResNetBottleNeckLayer(\n",
      "              (shortcut): ResNetShortCut(\n",
      "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResNetBottleNeckLayer(\n",
      "              (shortcut): Identity()\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResNetBottleNeckLayer(\n",
      "              (shortcut): Identity()\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResNetStage(\n",
      "          (layers): Sequential(\n",
      "            (0): ResNetBottleNeckLayer(\n",
      "              (shortcut): ResNetShortCut(\n",
      "                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResNetBottleNeckLayer(\n",
      "              (shortcut): Identity()\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResNetBottleNeckLayer(\n",
      "              (shortcut): Identity()\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (3): ResNetBottleNeckLayer(\n",
      "              (shortcut): Identity()\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): ResNetStage(\n",
      "          (layers): Sequential(\n",
      "            (0): ResNetBottleNeckLayer(\n",
      "              (shortcut): ResNetShortCut(\n",
      "                (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResNetBottleNeckLayer(\n",
      "              (shortcut): Identity()\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResNetBottleNeckLayer(\n",
      "              (shortcut): Identity()\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (3): ResNetBottleNeckLayer(\n",
      "              (shortcut): Identity()\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (4): ResNetBottleNeckLayer(\n",
      "              (shortcut): Identity()\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (5): ResNetBottleNeckLayer(\n",
      "              (shortcut): Identity()\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): ResNetStage(\n",
      "          (layers): Sequential(\n",
      "            (0): ResNetBottleNeckLayer(\n",
      "              (shortcut): ResNetShortCut(\n",
      "                (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResNetBottleNeckLayer(\n",
      "              (shortcut): Identity()\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResNetBottleNeckLayer(\n",
      "              (shortcut): Identity()\n",
      "              (layer): Sequential(\n",
      "                (0): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (1): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): ReLU()\n",
      "                )\n",
      "                (2): ResNetConvLayer(\n",
      "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (activation): Identity()\n",
      "                )\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=2048, out_features=21, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model\")\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "\n",
    "print(model.classifier)\n",
    "\n",
    " # --- Điều chỉnh lớp phân loại cuối cùng ---\n",
    "    # ResNet50 trong Hugging Face có lớp phân loại cuối cùng là `classifier`.\n",
    "    # Kích thước đầu vào của lớp này thường là 2048 (đầu ra của Global Average Pooling).\n",
    "    # --> Thay thế nó bằng một lớp tuyến tính mới có số đầu ra bằng `num_classes`.\n",
    "\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "087490ad-960a-4c43-9f31-5be5df7053bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T09:35:00.022245Z",
     "iopub.status.busy": "2025-11-06T09:35:00.021649Z",
     "iopub.status.idle": "2025-11-06T09:35:00.026193Z",
     "shell.execute_reply": "2025-11-06T09:35:00.025551Z",
     "shell.execute_reply.started": "2025-11-06T09:35:00.022220Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=21, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.classifier[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb32b8-6439-48b7-9a83-970b2e879067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T09:43:48.543173Z",
     "iopub.status.busy": "2025-11-06T09:43:48.542652Z",
     "iopub.status.idle": "2025-11-06T09:53:08.162036Z",
     "shell.execute_reply": "2025-11-06T09:53:08.161062Z",
     "shell.execute_reply.started": "2025-11-06T09:43:48.543152Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Full training on cuda for 3 with 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training 1/3:  95%|█████████▍| 149/157 [01:52<00:05,  1.36it/s]/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Training 1/3: 100%|██████████| 157/157 [01:58<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training loss: 2.3558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 105/105 [01:25<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation metrics\n",
      "Accuracy: 0.2547\n",
      "Recall: 0.2379\n",
      "Precision: 0.2547\n",
      "F1: 0.2547\n",
      "Save new model version with accurcay = 0.2547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training 2/3:  54%|█████▎    | 84/157 [01:01<00:51,  1.41it/s]/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Training 2/3: 100%|██████████| 157/157 [01:54<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training loss: 1.8851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 105/105 [01:02<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation metrics\n",
      "Accuracy: 0.3351\n",
      "Recall: 0.3186\n",
      "Precision: 0.3351\n",
      "F1: 0.3351\n",
      "Save new model version with accurcay = 0.3351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training 3/3:  18%|█▊        | 28/157 [00:21<01:37,  1.33it/s]/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Training 3/3: 100%|██████████| 157/157 [01:54<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training loss: 1.5969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 105/105 [01:02<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation metrics\n",
      "Accuracy: 0.3340\n",
      "Recall: 0.3142\n",
      "Precision: 0.3340\n",
      "F1: 0.3340\n",
      "Training_finished\n",
      "Best model version is saved at /kaggle/working/checkpoints/best_model_assigment_02.pt with accuracy = 0.3350793175695899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    learning_rate=0.01,\n",
    "    epochs=10,\n",
    "    save_dir= '/kaggle/working/checkpoints/'\n",
    ")\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8539588,
     "sourceId": 13453298,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
