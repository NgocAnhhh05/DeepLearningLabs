{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de36df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b3ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VinaFoodDataLoader:\n",
    "    def __init__(self, batch_size=64, num_workers=2, data_dir='/kaggle/input/vinafood21/VinaFood21', input_image_size=224):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.data_dir = data_dir\n",
    "        self.input_image_size = input_image_size\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            # 1. Resize image into 224 x 224\n",
    "            transforms.Resize((input_image_size, input_image_size)),\n",
    "\n",
    "            # 2. Convert into PyTorch Tensor\n",
    "            transforms.ToTensor(),\n",
    "\n",
    "            # 3. Normalize\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def get_train_loader(self):\n",
    "        train_path = os.path.join(self.data_dir, 'train')\n",
    "        train_dataset = datasets.ImageFolder(root=train_path, transform=self.transform)\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "        print(f\"Loaded {len(train_dataset)} training samples from {train_path}. Found {len(train_dataset.classes)} classes\")\n",
    "        self.num_classes = len(train_dataset.classes)\n",
    "        return train_loader\n",
    "\n",
    "        # Mỗi thư mục con tương ứng với 1 nhãn (class) -> gán label cho từng ảnh dựa theo thứ tự thư mục con được sắp xếp alphabetically\n",
    "\n",
    "    def get_test_loader(self):\n",
    "        test_path = os.path.join(self.data_dir, 'test')\n",
    "        test_dataset = datasets.ImageFolder(root=test_path, transform=self.transform)\n",
    "        test_loader = DataLoader(dataset=test_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n",
    "        print(f\"Loaded {len(test_dataset)} test samples from {test_path}\")\n",
    "        return test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, ch1x1_after_pooling):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "\n",
    "            ch1x1 (int): Number of output channels for the 1x1 convolution branch.\n",
    "\n",
    "            ch3x3red (int): Number of output channels for the 1x1 convolution (reduction) before the 3x3 convolution.\n",
    "\n",
    "            ch3x3 (int): Number of output channels for the 3x3 convolution branch.\n",
    "\n",
    "            ch5x5red (int): Number of output channels for the 1x1 convolution (reduction) before the 5x5 convolution.\n",
    "\n",
    "            ch5x5 (int): Number of output channels for the 5x5 convolution branch.\n",
    "\n",
    "            ch1x1_after_pooling (int): Number of output channels for the 1x1 convolution after the pooling operation.\n",
    "        \"\"\"\n",
    "        super(Inception, self).__init__()\n",
    "        # Branch 1: 1x1 Conv\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=ch1x1, kernel_size=1),\n",
    "            nn.ReLU(True) # set 0 for value < 0 (inplace)\n",
    "        )\n",
    "\n",
    "        # Branch 2: 1x1 Conv -> 3x3 Conv, pad 1\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=ch3x3red, kernel_size=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=ch3x3red, out_channels=ch3x3, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Brach 3: 1x1 Conv -> 5x5 Conv, pad 2\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=ch5x5red, kernel_size=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=ch5x5red, out_channels=ch5x5, kernel_size=5, padding=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Brach 4: 3x3MaxPool, pad 1 -> 1x1 Conv\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
    "            # có padding=1 -> giữ nguyên kích thước\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=ch1x1_after_pooling, kernel_size=1),\n",
    "            nn.ReLU(True)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass just for Inception block\n",
    "        Return:\n",
    "            torch.Tensor: The concatenated ouput tensor from all branches\n",
    "        \"\"\"\n",
    "        branch_1 = self.branch1(x)\n",
    "        branch_2 = self.branch2(x)\n",
    "        branch_3 = self.branch3(x)\n",
    "        branch_4 = self.branch4(x)\n",
    "\n",
    "        return torch.cat([branch_1, branch_2, branch_3, branch_4], 1)\n",
    "\n",
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self, num_clases):\n",
    "        super(GoogleNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
    "        # in_channels cuar conv1 = 3 vì ảnh màu -> RGB\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=64,out_channels=192, kernel_size=3, padding=1),\n",
    "            # Add padding to maintain kernel size = 56\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "\n",
    "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "\n",
    "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "\n",
    "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "\n",
    "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "\n",
    "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        # Input (N, 1024, 7, 7) -> Output (N, 1024, 1, 1) -> Flatten to (N, 1024)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc = nn.Linear(in_features=1024, out_features=num_clases)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Inception 3a, 3b\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Inception 4\n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # Inception 5\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        # Flatten the output from (N, 1024, 1, 1) to (N, 1024)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        return logits, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6f6fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            _, probabilities = model(data)\n",
    "            predictions = probabilities.argmax(dim=1)\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    print(\"Overall evaluation metrics\")\n",
    "    overall_accuracy = accuracy_score(all_targets, all_preds)\n",
    "    print(f\"Accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    "    overall_recall = recall_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    print(f\"Recall: {overall_recall:.4f}\")\n",
    "\n",
    "    overall_precision = precision_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    print(f\"Precision: {overall_accuracy:.4f}\")\n",
    "\n",
    "    overall_f1 = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    print(f\"F1: {overall_accuracy:.4f}\")\n",
    "\n",
    "    num_classes = len(np.unique(all_targets))\n",
    "    per_class_results = {}\n",
    "\n",
    "    print(f\"Per-class evaluation metrics\")\n",
    "    for i in range (num_classes):\n",
    "        class_target = (all_targets == i).astype(int)\n",
    "        class_pred = (all_preds == i).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(class_target, class_pred)\n",
    "        precision = precision_score(class_target, class_pred, zero_division=0)\n",
    "        recall = recall_score(class_target, class_pred, zero_division=0)\n",
    "        f1 = f1_score(class_target, class_pred, zero_division=0)\n",
    "\n",
    "        per_class_results[i] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "        print(f\"Class {i}: \\n Accuracy: {accuracy:.4f} \\n Recall: {recall:.4f} \\n Precision: {precision:.4f} \\n F1: {f1:.4f}\")\n",
    "    return {\n",
    "        'overall': {\n",
    "            'accuracy': overall_accuracy,\n",
    "            'precision': overall_precision,\n",
    "            'recall': overall_recall,\n",
    "            'f1': overall_f1\n",
    "        },\n",
    "        'per_class': per_class_results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e29943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, test_loader, device, learning_rate=0.01, epochs=10, save_dir='./checkpoints'):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.best_accuracy = 0.0\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(self.train_loader, desc=f'Training {epoch}/{self.epochs}')):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            _,logits = self.model(data)\n",
    "            loss = self.criterion(logits, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss\n",
    "\n",
    "        avg_loss = total_loss/len(self.train_loader)\n",
    "        print(f\"Epoch {epoch} Training loss: {avg_loss:.4f}\")\n",
    "        return avg_loss\n",
    "\n",
    "    def train(self):\n",
    "        print(f\"Full training on {self.device} for {self.epochs} with {self.learning_rate}\")\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            self.train_epoch(epoch)\n",
    "\n",
    "            metrics = evaluate_model(self.model, self.test_loader, self.device)\n",
    "            current_accuracy = metrics['overall']['accuracy']\n",
    "            if current_accuracy > self.best_accuracy:\n",
    "                self.best_accuracy = current_accuracy\n",
    "                model_path = os.path.join(self.save_dir, 'best_model_assigment_02.pt')\n",
    "                torch.save(self.model.state_dict(), model_path)\n",
    "                print(f\"Save new model version with accurcay = {self.best_accuracy:.4f}\")\n",
    "        print(\"Training_finished\")\n",
    "        print(f\"Best model version is saved at {model_path} with accuracy = {self.best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ead30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "print(\"Load data\")\n",
    "data_loader = VinaFoodDataLoader()\n",
    "train_loader = data_loader.get_train_loader()\n",
    "test_loader = data_loader.get_test_loader()\n",
    "\n",
    "num_classes = data_loader.num_classes\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "print(\"Build model\")\n",
    "model = GoogleNet(num_clases=num_classes)\n",
    "print(model)\n",
    "\n",
    "print(\"Start training\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    learning_rate=0.01,\n",
    "    epochs=10,\n",
    "    save_dir= './checkpoints'\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "print(\"Evaluate with best model\")\n",
    "best_model_path = './checkpoints/best_model_assignment_02.pt'\n",
    "final_model = GoogleNet(num_clases=num_classes).to(device)\n",
    "final_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "final_metrics = evaluate_model(\n",
    "    model=final_model,\n",
    "    data_loader=test_loader,\n",
    "    device=device\n",
    ")\n",
    "print(\"Final overall metrics\")\n",
    "for k, v in final_model['overall'].items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"Final per-class metrics\")\n",
    "for label, metrics in final_metrics['per_class'].items():\n",
    "    print (f\"Class {label}: \\n Acc: {metrics['accuracy']:.4f} \\n Precision: {metrics['precision']:.4f} \\n Recall: {metrics['recall']:.4f} \\n F1: {metrics['f1']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vietlegal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
